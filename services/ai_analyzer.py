import pandas as pd
import os
import json
import httpx
import re
from typing import AsyncGenerator
from dotenv import load_dotenv
from utils.logger import get_logger
from utils.api_utils import APIUtils
from datetime import datetime

# è·å–æ—¥å¿—å™¨
logger = get_logger()

class AIAnalyzer:
    """
    å¼‚æ­¥AIåˆ†ææœåŠ¡
    è´Ÿè´£è°ƒç”¨AI APIå¯¹è‚¡ç¥¨æ•°æ®è¿›è¡Œåˆ†æ
    """
    
    def __init__(self, custom_api_url=None, custom_api_key=None, custom_api_model=None, custom_api_timeout=None):
        """
        åˆå§‹åŒ–AIåˆ†ææœåŠ¡
        
        Args:
            custom_api_url: è‡ªå®šä¹‰API URL
            custom_api_key: è‡ªå®šä¹‰APIå¯†é’¥
            custom_api_model: è‡ªå®šä¹‰APIæ¨¡å‹
            custom_api_timeout: è‡ªå®šä¹‰APIè¶…æ—¶æ—¶é—´
        """
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        
        # è®¾ç½®APIé…ç½®
        self.API_URL = custom_api_url or os.getenv('API_URL')
        self.API_KEY = custom_api_key or os.getenv('API_KEY')
        self.API_MODEL = custom_api_model or os.getenv('API_MODEL', 'gpt-3.5-turbo')
        self.API_TIMEOUT = int(custom_api_timeout or os.getenv('API_TIMEOUT', 60))
        
        logger.debug(f"åˆå§‹åŒ–AIAnalyzer: API_URL={self.API_URL}, API_MODEL={self.API_MODEL}, API_KEY={'å·²æä¾›' if self.API_KEY else 'æœªæä¾›'}, API_TIMEOUT={self.API_TIMEOUT}")
    
    async def get_ai_analysis(self, df: pd.DataFrame, stock_code: str, market_type: str = 'A', stream: bool = False) -> AsyncGenerator[str, None]:
        """
        å¯¹è‚¡ç¥¨æ•°æ®è¿›è¡ŒAIåˆ†æ
        
        Args:
            df: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„DataFrame
            stock_code: è‚¡ç¥¨ä»£ç 
            market_type: å¸‚åœºç±»å‹ï¼Œé»˜è®¤ä¸º'A'è‚¡
            stream: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
            
        Returns:
            å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œç”Ÿæˆåˆ†æç»“æœå­—ç¬¦ä¸²
        """
        try:
            logger.info(f"å¼€å§‹AIåˆ†æ {stock_code}, æµå¼æ¨¡å¼: {stream}")
            
            # æå–å…³é”®æŠ€æœ¯æŒ‡æ ‡
            latest_data = df.iloc[-1]
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            rsi = latest_data.get('RSI')
            price = latest_data.get('Close')
            price_change = latest_data.get('Change')
            
            # ç¡®å®šMAè¶‹åŠ¿
            ma_trend = 'UP' if latest_data.get('MA5', 0) > latest_data.get('MA20', 0) else 'DOWN'
            
            # ç¡®å®šMACDä¿¡å·
            macd = latest_data.get('MACD', 0)
            macd_signal = latest_data.get('MACD_Signal', 0)
            macd_signal_type = 'BUY' if macd > macd_signal else 'SELL'
            
            # ç¡®å®šæˆäº¤é‡çŠ¶æ€
            volume_ratio = latest_data.get('Volume_Ratio', 1)
            volume_status = 'HIGH' if volume_ratio > 1.5 else ('LOW' if volume_ratio < 0.5 else 'NORMAL')
            
            # AI åˆ†æå†…å®¹
            # æœ€è¿‘14å¤©çš„è‚¡ç¥¨æ•°æ®è®°å½•
            recent_data = df.tail(14).to_dict('records')
            
            # åŒ…å«trend, volatility, volume_trend, rsi_levelçš„å­—å…¸
            technical_summary = {
                'trend': 'upward' if df.iloc[-1]['MA5'] > df.iloc[-1]['MA20'] else 'downward',
                'volatility': f"{df.iloc[-1]['Volatility']:.2f}%",
                'volume_trend': 'increasing' if df.iloc[-1]['Volume_Ratio'] > 1 else 'decreasing',
                'rsi_level': df.iloc[-1]['RSI']
            }
            
            # åˆ†ææ—¥æœŸï¼šç³»ç»Ÿè¿›è¡Œåˆ†æçš„æ—¥æœŸï¼ˆå½“å‰æ—¥æœŸï¼‰
            analysis_date = datetime.now().strftime('%Y-%m-%d')
            
            # ä»·æ ¼æ—¥æœŸï¼šæ•°æ®çš„æœ€æ–°æ—¥æœŸ
            if not df.empty and hasattr(df.index, 'max'):
                try:
                    latest_data_date = df.index.max()
                    if pd.notna(latest_data_date) and hasattr(latest_data_date, 'strftime'):
                        price_date = latest_data_date.strftime('%Y-%m-%d')
                        
                        # è®¡ç®—æ•°æ®å»¶è¿Ÿå¤©æ•°
                        current_date = datetime.now().date()
                        data_date = latest_data_date.date() if hasattr(latest_data_date, 'date') else pd.to_datetime(latest_data_date).date()
                        days_delay = (current_date - data_date).days
                        
                        logger.info(f"ğŸ“… [æ—¥æœŸä¿¡æ¯] åˆ†ææ—¥æœŸ: {analysis_date}, ä»·æ ¼æ—¥æœŸ: {price_date}, æ•°æ®å»¶è¿Ÿ: {days_delay}å¤©")
                    else:
                        price_date = analysis_date
                        days_delay = 0
                except Exception as e:
                    price_date = analysis_date
                    days_delay = 0
            else:
                price_date = analysis_date
                days_delay = 0

            # åœ¨AIæç¤ºè¯ä¸­æ·»åŠ ä¸¤ä¸ªæ—¥æœŸçš„è¯´æ˜
            data_timeliness_note = f"""
æ•°æ®æ—¶æ•ˆæ€§è¯´æ˜ï¼š
- åˆ†ææ‰§è¡Œæ—¥æœŸï¼š{analysis_date}
- ä»·æ ¼æ•°æ®æ—¥æœŸï¼š{price_date}
- æ•°æ®å»¶è¿Ÿï¼š{days_delay}å¤©
{"- æ³¨æ„ï¼šä»·æ ¼æ•°æ®å¯èƒ½å› å‘¨æœ«ã€èŠ‚å‡æ—¥æˆ–æ•°æ®æºæ›´æ–°å»¶è¿Ÿè€Œä¸æ˜¯æœ€æ–°çš„" if days_delay > 0 else "- æ•°æ®ä¸ºæœ€æ–°"}
"""
            
            # æ ¹æ®å¸‚åœºç±»å‹è°ƒæ•´åˆ†ææç¤º
            if market_type in ['ETF', 'LOF']:
                prompt = f"""
                åˆ†æåŸºé‡‘ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘14æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. å‡€å€¼èµ°åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å¯¹å‡€å€¼çš„å½±å“
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡å’ŒæŠ˜æº¢ä»·åˆ†æï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸå‡€å€¼é¢„æµ‹
                5. å…³é”®ä»·æ ¼ä½åˆ†æ
                6. ç”³è´­èµå›å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºè¡¨ç°è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            elif market_type == 'US':
                prompt = f"""
                åˆ†æç¾è‚¡ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘14æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. è¶‹åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼Œç¾å…ƒè®¡ä»·ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å«ä¹‰
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡å’Œç¾è‚¡å¸‚åœºç‰¹æœ‰é£é™©ï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸç›®æ ‡ä»·ä½ï¼ˆç¾å…ƒï¼‰
                5. å…³é”®æŠ€æœ¯ä½åˆ†æ
                6. å…·ä½“äº¤æ˜“å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’Œç¾è‚¡å¸‚åœºç‰¹ç‚¹è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            elif market_type == 'HK':
                prompt = f"""
                åˆ†ææ¸¯è‚¡ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘14æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. è¶‹åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼Œæ¸¯å¸è®¡ä»·ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å«ä¹‰
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡å’Œæ¸¯è‚¡å¸‚åœºç‰¹æœ‰é£é™©ï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸç›®æ ‡ä»·ä½ï¼ˆæ¸¯å¸ï¼‰
                5. å…³é”®æŠ€æœ¯ä½åˆ†æ
                6. å…·ä½“äº¤æ˜“å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’Œæ¸¯è‚¡å¸‚åœºç‰¹ç‚¹è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            else:  # Aè‚¡
                prompt = f"""
                åˆ†æAè‚¡ {stock_code}ï¼š

                æŠ€æœ¯æŒ‡æ ‡æ¦‚è¦ï¼š
                {technical_summary}
                
                è¿‘14æ—¥äº¤æ˜“æ•°æ®ï¼š
                {recent_data}
                
                è¯·æä¾›ï¼š
                1. è¶‹åŠ¿åˆ†æï¼ˆåŒ…å«æ”¯æ’‘ä½å’Œå‹åŠ›ä½ï¼‰
                2. æˆäº¤é‡åˆ†æåŠå…¶å«ä¹‰
                3. é£é™©è¯„ä¼°ï¼ˆåŒ…å«æ³¢åŠ¨ç‡åˆ†æï¼‰
                4. çŸ­æœŸå’Œä¸­æœŸç›®æ ‡ä»·ä½
                5. å…³é”®æŠ€æœ¯ä½åˆ†æ
                6. å…·ä½“äº¤æ˜“å»ºè®®ï¼ˆåŒ…å«æ­¢æŸä½ï¼‰
                
                è¯·åŸºäºæŠ€æœ¯æŒ‡æ ‡å’ŒAè‚¡å¸‚åœºç‰¹ç‚¹è¿›è¡Œåˆ†æï¼Œç»™å‡ºå…·ä½“æ•°æ®æ”¯æŒã€‚
                """
            
            # æ ¼å¼åŒ–API URL
            api_url = APIUtils.format_api_url(self.API_URL)
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            request_data = {
                "model": self.API_MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.7,
                "stream": stream
            }
            
            # å‡†å¤‡è¯·æ±‚å¤´
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.API_KEY}"
            }
            
            # å¼‚æ­¥è¯·æ±‚API
            async with httpx.AsyncClient(timeout=self.API_TIMEOUT) as client:
                # è®°å½•è¯·æ±‚
                logger.debug(f"å‘é€AIè¯·æ±‚: URL={api_url}, MODEL={self.API_MODEL}, STREAM={stream}")
                
                # å…ˆå‘é€æŠ€æœ¯æŒ‡æ ‡æ•°æ®
                yield json.dumps({
                    "stock_code": stock_code,
                    "status": "analyzing",
                    "rsi": rsi,
                    "price": price,
                    "price_change": price_change,
                    "ma_trend": ma_trend,
                    "macd_signal": macd_signal_type,
                    "volume_status": volume_status,
                    "analysis_date": analysis_date,   # åˆ†ææ—¥æœŸ
                    "price_date": price_date          # ä»·æ ¼æ—¥æœŸ
                })
                
                if stream:
                    # æµå¼å“åº”å¤„ç†
                    async with client.stream("POST", api_url, json=request_data, headers=headers) as response:
                        if response.status_code != 200:
                            error_text = await response.aread()
                            error_data = json.loads(error_text)
                            error_message = error_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                            logger.error(f"AI APIè¯·æ±‚å¤±è´¥: {response.status_code} - {error_message}")
                            yield json.dumps({
                                "stock_code": stock_code,
                                "error": f"APIè¯·æ±‚å¤±è´¥: {error_message}",
                                "status": "error"
                            })
                            return
                            
                        # å¤„ç†æµå¼å“åº”
                        buffer = ""
                        collected_messages = []
                        chunk_count = 0
                        
                        async for chunk in response.aiter_text():
                            if chunk:
                                # åˆ†å‰²å¤šè¡Œå“åº”ï¼ˆå¤„ç†æŸäº›APIå¯èƒ½åœ¨ä¸€ä¸ªchunkä¸­è¿”å›å¤šè¡Œï¼‰
                                lines = chunk.strip().split('\n')
                                for line in lines:
                                    line = line.strip()
                                    if not line:
                                        continue
                                        
                                    # å¤„ç†ä»¥data:å¼€å¤´çš„è¡Œ
                                    if line.startswith("data: "):
                                        line = line[6:]  # å»é™¤"data: "å‰ç¼€
                                     
                                    if line == "[DONE]":
                                        logger.debug("æ”¶åˆ°æµç»“æŸæ ‡è®° [DONE]")
                                        continue
                                        
                                    try:
                                        # å¤„ç†ç‰¹æ®Šé”™è¯¯æƒ…å†µ
                                        if "error" in line.lower():
                                            error_msg = line
                                            try:
                                                error_data = json.loads(line)
                                                error_msg = error_data.get("error", line)
                                            except:
                                                pass
                                            
                                            logger.error(f"æµå¼å“åº”ä¸­æ”¶åˆ°é”™è¯¯: {error_msg}")
                                            yield json.dumps({
                                                "stock_code": stock_code,
                                                "error": f"æµå¼å“åº”é”™è¯¯: {error_msg}",
                                                "status": "error"
                                            })
                                            continue
                                        
                                        # å°è¯•è§£æJSON
                                        chunk_data = json.loads(line)
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰finish_reason
                                        finish_reason = chunk_data.get("choices", [{}])[0].get("finish_reason")
                                        if finish_reason == "stop":
                                            logger.debug("æ”¶åˆ°finish_reason=stopï¼Œæµç»“æŸ")
                                            continue
                                        
                                        # è·å–deltaå†…å®¹
                                        delta = chunk_data.get("choices", [{}])[0].get("delta", {})
                                        
                                        # æ£€æŸ¥deltaæ˜¯å¦ä¸ºç©ºå¯¹è±¡
                                        if not delta or delta == {}:
                                            logger.debug("æ”¶åˆ°ç©ºçš„deltaå¯¹è±¡ï¼Œè·³è¿‡")
                                            continue
                                        
                                        content = delta.get("content", "")
                                        
                                        if content:
                                            chunk_count += 1
                                            buffer += content
                                            collected_messages.append(content)
                                            
                                            # ç›´æ¥å‘é€æ¯ä¸ªå†…å®¹ç‰‡æ®µï¼Œä¸ç´¯ç§¯
                                            yield json.dumps({
                                                "stock_code": stock_code,
                                                "ai_analysis_chunk": content,
                                                "status": "analyzing"
                                            })
                                    except json.JSONDecodeError:
                                        # è®°å½•è§£æé”™è¯¯å¹¶å°è¯•æ¢å¤
                                        logger.error(f"JSONè§£æé”™è¯¯ï¼Œå—å†…å®¹: {line}")
                                        
                                        # å¦‚æœæ˜¯ç‰¹å®šé”™è¯¯æ¨¡å¼ï¼Œå¤„ç†å®ƒ
                                        if "streaming failed after retries" in line.lower():
                                            logger.error("æ£€æµ‹åˆ°æµå¼ä¼ è¾“å¤±è´¥")
                                            yield json.dumps({
                                                "stock_code": stock_code,
                                                "error": "æµå¼ä¼ è¾“å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
                                                "status": "error"
                                            })
                                            return
                                        continue
                        
                        logger.info(f"AIæµå¼å¤„ç†å®Œæˆï¼Œå…±æ”¶åˆ° {chunk_count} ä¸ªå†…å®¹ç‰‡æ®µï¼Œæ€»é•¿åº¦: {len(buffer)}")
                        
                        # å¦‚æœbufferä¸ä¸ºç©ºä¸”ä¸ä»¥æ¢è¡Œç¬¦ç»“æŸï¼Œå‘é€ä¸€ä¸ªæ¢è¡Œç¬¦
                        if buffer and not buffer.endswith('\n'):
                            logger.debug("å‘é€æ¢è¡Œç¬¦")
                            yield json.dumps({
                                "stock_code": stock_code,
                                "ai_analysis_chunk": "\n",
                                "status": "analyzing"
                            })
                        
                        # å®Œæ•´çš„åˆ†æå†…å®¹
                        full_content = buffer
                        
                        # å°è¯•ä»åˆ†æå†…å®¹ä¸­æå–æŠ•èµ„å»ºè®®
                        recommendation = self._extract_recommendation(full_content)
                        
                        # è®¡ç®—åˆ†æè¯„åˆ†
                        score = self._calculate_analysis_score(full_content, technical_summary)
                        
                        # å‘é€å®ŒæˆçŠ¶æ€å’Œè¯„åˆ†ã€å»ºè®®
                        yield json.dumps({
                            "stock_code": stock_code,
                            "status": "completed",
                            "score": score,
                            "recommendation": recommendation,
                            "analysis_date": analysis_date,   # åˆ†ææ—¥æœŸ
                            "price_date": price_date          # ä»·æ ¼æ—¥æœŸ
                        })
                else:
                    # éæµå¼å“åº”å¤„ç†
                    response = await client.post(api_url, json=request_data, headers=headers)
                    
                    if response.status_code != 200:
                        error_data = response.json()
                        error_message = error_data.get('error', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                        logger.error(f"AI APIè¯·æ±‚å¤±è´¥: {response.status_code} - {error_message}")
                        yield json.dumps({
                            "stock_code": stock_code,
                            "error": f"APIè¯·æ±‚å¤±è´¥: {error_message}",
                            "status": "error"
                        })
                        return
                    
                    response_data = response.json()
                    analysis_text = response_data.get("choices", [{}])[0].get("message", {}).get("content", "")
                    
                    # å°è¯•ä»åˆ†æå†…å®¹ä¸­æå–æŠ•èµ„å»ºè®®
                    recommendation = self._extract_recommendation(analysis_text)
                    
                    # è®¡ç®—åˆ†æè¯„åˆ†
                    score = self._calculate_analysis_score(analysis_text, technical_summary)
                    
                    # å‘é€å®Œæ•´çš„åˆ†æç»“æœ
                    yield json.dumps({
                        "stock_code": stock_code,
                        "status": "completed",
                        "analysis": analysis_text,
                        "score": score,
                        "recommendation": recommendation,
                        "rsi": rsi,
                        "price": price,
                        "price_change": price_change,
                        "ma_trend": ma_trend,
                        "macd_signal": macd_signal_type,
                        "volume_status": volume_status,
                        "analysis_date": analysis_date,   # åˆ†ææ—¥æœŸ
                        "price_date": price_date          # ä»·æ ¼æ—¥æœŸ
                    })
                    
        except Exception as e:
            logger.error(f"AIåˆ†æå‡ºé”™: {str(e)}", exc_info=True)
            yield json.dumps({
                "stock_code": stock_code,
                "error": f"åˆ†æå‡ºé”™: {str(e)}",
                "status": "error"
            })
            
    def _extract_recommendation(self, analysis_text: str) -> str:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–æŠ•èµ„å»ºè®®"""
        # æŸ¥æ‰¾æŠ•èµ„å»ºè®®éƒ¨åˆ†
        investment_advice_pattern = r"##\s*æŠ•èµ„å»ºè®®\s*\n(.*?)(?:\n##|\Z)"
        match = re.search(investment_advice_pattern, analysis_text, re.DOTALL)
        
        if match:
            advice_text = match.group(1).strip()
            
            # æå–å…³é”®å»ºè®®
            if "ä¹°å…¥" in advice_text or "å¢æŒ" in advice_text:
                return "ä¹°å…¥"
            elif "å–å‡º" in advice_text or "å‡æŒ" in advice_text:
                return "å–å‡º"
            elif "æŒæœ‰" in advice_text:
                return "æŒæœ‰"
            else:
                return "è§‚æœ›"
        
        return "è§‚æœ›"  # é»˜è®¤å»ºè®®
        
    def _calculate_analysis_score(self, analysis_text: str, technical_summary: dict) -> int:
        """è®¡ç®—åˆ†æè¯„åˆ†"""
        score = 50  # åŸºç¡€åˆ†æ•°
        
        # æ ¹æ®æŠ€æœ¯æŒ‡æ ‡è°ƒæ•´åˆ†æ•°
        if technical_summary['trend'] == 'upward':
            score += 10
        else:
            score -= 10
            
        if technical_summary['volume_trend'] == 'increasing':
            score += 5
        else:
            score -= 5
            
        rsi = technical_summary['rsi_level']
        if rsi < 30:  # è¶…å–
            score += 15
        elif rsi > 70:  # è¶…ä¹°
            score -= 15
            
        # æ ¹æ®åˆ†ææ–‡æœ¬ä¸­çš„å…³é”®è¯è°ƒæ•´åˆ†æ•°
        if "å¼ºçƒˆä¹°å…¥" in analysis_text or "æ˜¾è‘—ä¸Šæ¶¨" in analysis_text:
            score += 20
        elif "ä¹°å…¥" in analysis_text or "çœ‹æ¶¨" in analysis_text:
            score += 10
        elif "å¼ºçƒˆå–å‡º" in analysis_text or "æ˜¾è‘—ä¸‹è·Œ" in analysis_text:
            score -= 20
        elif "å–å‡º" in analysis_text or "çœ‹è·Œ" in analysis_text:
            score -= 10
            
        # ç¡®ä¿åˆ†æ•°åœ¨0-100èŒƒå›´å†…
        return max(0, min(100, score))
    
    def _truncate_json_for_logging(self, json_obj, max_length=500):
        """
        æˆªæ–­JSONå¯¹è±¡ä»¥ä¾¿è®°å½•æ—¥å¿—
        
        Args:
            json_obj: JSONå¯¹è±¡
            max_length: æœ€å¤§é•¿åº¦
            
        Returns:
            æˆªæ–­åçš„å­—ç¬¦ä¸²
        """
        json_str = json.dumps(json_obj, ensure_ascii=False)
        if len(json_str) <= max_length:
            return json_str
        return json_str[:max_length] + "..." 